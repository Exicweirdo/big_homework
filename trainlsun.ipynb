{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cYp_0vvbv8Vi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#def convtrans resblock\n",
    "class Tresblock1(torch.nn.Module):\n",
    "    def __init__(self, in_channels:int, out_channels:int, kernel_size, device='cpu', stride=1) -> None:\n",
    "        super(Tresblock1, self).__init__()\n",
    "        self.convT2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, \n",
    "        padding=(kernel_size-stride)//2, device=device)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels, device=device)\n",
    "        self.identity = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=stride),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, padding='same', bias=False, device=device)\n",
    "        )\n",
    "        self.ReLU = nn.ReLU(True)\n",
    "    def forward(self, x):\n",
    "        hid = self.convT2d(x)\n",
    "        hid = self.batchnorm(hid)\n",
    "        out = self.ReLU(hid)  + self.identity(x)\n",
    "        return out\n",
    "\n",
    "class Tresblock2(torch.nn.Module):\n",
    "    def __init__(self, in_channels:int, out_channels:int, kernel_size, device='cpu', stride=1) -> None:\n",
    "        super(Tresblock2, self).__init__()\n",
    "        self.convT2d1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, \n",
    "        padding=1, output_padding=1, device=device, bias=False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(out_channels, device=device)\n",
    "        self.convT2d2 = nn.ConvTranspose2d(out_channels, out_channels, kernel_size, stride=1, \n",
    "        padding=1, device=device, bias=False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(out_channels, device=device)\n",
    "        self.identity = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=stride),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, padding='same', bias=False, device=device)\n",
    "        )\n",
    "        self.ReLU = nn.ReLU(True)\n",
    "    def forward(self, x):\n",
    "        hid = self.convT2d1(x)\n",
    "        hid = self.batchnorm1(hid)\n",
    "        hid = self.ReLU(hid)\n",
    "        hid = self.convT2d2(hid)\n",
    "        hid = self.batchnorm2(hid) + self.identity(x)\n",
    "        out = self.ReLU(hid)\n",
    "        return out\n",
    "#resblock without bn\n",
    "class resblock(torch.nn.Module):\n",
    "    def __init__(self, in_channel:int, out_channel:int, stride:int = 1, dilation:int=1, device = 'cpu') -> None:\n",
    "        super(resblock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False, device=device)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, padding='same', bias=False, device=device)\n",
    "        self.downsample = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=stride, bias=False, device=device)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out+= self.downsample(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "class resblock_bn(torch.nn.Module):\n",
    "    def __init__(self, in_channel:int, out_channel:int, stride:int = 1, dilation:int=1, device = 'cpu') -> None:\n",
    "        super(resblock_bn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False, device=device)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel, device=device)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, padding='same', bias=False, device=device)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel, device=device)\n",
    "        self.downsample = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=stride, bias=False, device=device)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out) + self.downsample(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "# generatar model\n",
    "#-------------------------------structure of generator---------------------------------------\n",
    "#preprocess step(linear, relu)   input:batchsize*input_shape    output:batchsize*channel*n*n\n",
    "#111111111111111111111111111111111111111111111111111111111111111\n",
    "#1Tresblock1*n inchannel  outchannel if kernelsize=2\n",
    "#1  convT2d\n",
    "#1   batchnorm\n",
    "#1   ReLU\n",
    "#1   out + upsampling(x)\n",
    "#1 Tresblock2*n inchannel outchannel if kernelsize=3    <the original form in paper but larger\n",
    "#1   convT2d\n",
    "#1   batchnorm\n",
    "#1   ReLU\n",
    "#1   convT2d\n",
    "#1   batchnorm + upsampling(x)\n",
    "#1   ReLU\n",
    "#1111111111111111111111111111111111111111111111111111111111111111\n",
    "#output layer inchannel   3*figsize*figsize\n",
    "#   convT2d\n",
    "#   Tanh\n",
    "#--------------------------------------------------------------------------------------------\n",
    "#Caution: output is in range [-1,1], should be convert linearly into [0,1] or [0,255]\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, input_shape:int, blocklist, figsize:int, device='cpu', Simple = False) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        self.device = device\n",
    "        in_channel = blocklist[0]['out_channel']*2\n",
    "        self.input_channel = in_channel\n",
    "        Layers = []\n",
    "        self.input_size = figsize\n",
    "        for layer in blocklist:\n",
    "            #change channels\n",
    "            #apply resblock\n",
    "            if Simple:\n",
    "                Layers.extend([\n",
    "                    nn.ConvTranspose2d(in_channel, layer['out_channel'], layer['kernel'], layer['stride'], padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(layer['out_channel']),\n",
    "                    nn.ReLU(True),\n",
    "                ])\n",
    "            else:\n",
    "                if layer['kernel']==2:\n",
    "                    Layers.append(Tresblock1(in_channel, layer['out_channel'], kernel_size=2, stride=2, device=device))\n",
    "                elif layer['kernel']==3:\n",
    "                    Layers.append(Tresblock2(in_channel, layer['out_channel'], kernel_size=3, stride=2, device=device))\n",
    "            \n",
    "            self.input_size = self.input_size//layer['stride']\n",
    "            in_channel = layer['out_channel']\n",
    "        #give rgb data\n",
    "        Layers.extend([\n",
    "            nn.ConvTranspose2d(in_channel, 3, kernel_size=2, stride=2, device=device),\n",
    "            nn.Tanh()\n",
    "        ])\n",
    "        self.input_size = self.input_size//2\n",
    "        self.preprocess = nn.Sequential(\n",
    "            nn.Linear(input_shape, blocklist[0]['out_channel']*2*self.input_size**2, device=device),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.Seq = nn.Sequential(*Layers)\n",
    "        self.init_parameters()\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        res_in = self.preprocess(x).view(-1, self.input_channel, self.input_size, self.input_size)\n",
    "        out = self.Seq(res_in)\n",
    "        return out\n",
    "\n",
    "    def init_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv2d, nn.ConvTranspose2d)):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "        return 0\n",
    "# generatar model\n",
    "#-------------------------------structure of discriminator---------------------------------------\n",
    "#recieve batchsize*3*input_size*input_size tensor as input(generator output, img should normalized to [0,1] or N(0.5,0.5))\n",
    "#if use_res==True\n",
    "#   resblock*n inchannel(first is 3)  outchannel\n",
    "#       conv2d(no bias)\n",
    "#       ReLU\n",
    "#       conv2d(no bias)\n",
    "#       out + downsampling(x)\n",
    "#       ReLU\n",
    "#else\n",
    "#   [conv2d\n",
    "#   LeakyReLU]*n\n",
    "#\n",
    "#output layer\n",
    "#   linear\n",
    "#--------------------------------------------------------------------------------------------\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, input_size:int, blocklist, device = 'cpu', use_res = False) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.device = device\n",
    "        #self.preprocess = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding='same', device=device)\n",
    "        in_channel = 3\n",
    "        self.figsize = input_size\n",
    "        Layers = []\n",
    "        if use_res==False:\n",
    "            for layer in blocklist:\n",
    "                #change channels\n",
    "                Layers.extend([\n",
    "                    nn.Conv2d(in_channel, layer['out_channel'], layer['kernel'],stride=layer['stride'], padding=1, device=device),\n",
    "                    nn.LeakyReLU()\n",
    "                ])\n",
    "                #resampling\n",
    "                in_channel = layer['out_channel']\n",
    "                self.figsize = self.figsize//layer['stride']\n",
    "        elif use_res==True:\n",
    "            for layer in block_list:\n",
    "                Layers.append(resblock(in_channel, layer['out_channel'], stride=layer['stride'], device=device))\n",
    "                in_channel = layer['out_channel']\n",
    "                self.figsize = self.figsize//layer['stride']\n",
    "        elif use_res=='bn':\n",
    "            Layers.append(nn.Conv2d(in_channel, block_list[0]['out_channel'], 3, padding='same', bias=False, device=device))\n",
    "            Layers.append(nn.ReLU())\n",
    "            in_channel = block_list[0]['out_channel']\n",
    "            for layer in block_list:\n",
    "                Layers.append(resblock_bn(in_channel, layer['out_channel'], stride=layer['stride'], device=device))\n",
    "                in_channel = layer['out_channel']\n",
    "                self.figsize = self.figsize//layer['stride']\n",
    "        self.seq = nn.Sequential(*Layers)\n",
    "        self.outlinear = nn.Linear(in_features=self.figsize**2*in_channel, out_features=1,device=device)\n",
    "        self.outchannel = in_channel\n",
    "        self.init_parameters()\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        #res_in = self.preprocess(x)\n",
    "        res_out = self.seq(x)\n",
    "        out = self.outlinear(res_out.view(-1, self.figsize**2*self.outchannel))\n",
    "        return(out)\n",
    "    \n",
    "    def init_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "        return 0\n",
    "\n",
    "\n",
    "def get_param_num(model:nn.Module):\n",
    "    param_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_param_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return{'Total':param_num, 'Trainable':trainable_param_num}\n",
    "# using wgan-div to train discriminator with k and p\n",
    "def train_discrminator(model:Discriminator, real_data:torch.Tensor, fake_data:torch.Tensor, optimizer:torch.optim.Optimizer, k = 2, p = 6, device = 'cpu'):\n",
    "    model.train()\n",
    "    score_loss = model(fake_data).mean()-model(real_data).mean()\n",
    "    #compute gradient loss\n",
    "    mixconst = torch.rand(real_data.size(0), device=device)\n",
    "    x_mix = torch.tensordot(torch.diag(mixconst), real_data, dims=[[0],[0]]) \\\n",
    "        + torch.tensordot(torch.diag(1-mixconst), fake_data, dims=[[0],[0]])\n",
    "    x_mix.requires_grad_()\n",
    "    model.eval()\n",
    "    grad_mix = torch.autograd.grad(model(x_mix).sum(), x_mix, create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    model.train()\n",
    "    #grad_mix_check =  torch.autograd.grad(model(x_mix), x_mix, grad_outputs=torch.ones(x_mix.size()).to(device), create_graph=True, retain_graph=True)[0]\n",
    "    gradient_loss = (k*torch.sum(grad_mix**2, dim=[1,2,3])**(p/2)).mean()\n",
    "    #add loss\n",
    "    loss = score_loss + gradient_loss\n",
    "    #train\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return gradient_loss\n",
    "#train generator using discriminator\n",
    "def train_generator(g_model:Generator, d_model:Discriminator, randinput:torch.Tensor, optimizer:torch.optim.Optimizer):\n",
    "    g_model.train()\n",
    "    d_model.eval()\n",
    "    g_model.zero_grad()\n",
    "    loss = -d_model(g_model(randinput)).mean()#torch.sum(-d_model(g_model(randinput)))/batchsize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4P4n2upXv9r7",
    "outputId": "e0f8eaea-9c45-4898-ea45-cfc0afc6a486"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def plotsamp(samp, figname):\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot()\n",
    "  samp = np.transpose(samp, (1,2,0))\n",
    "  ax.imshow(samp)\n",
    "  if figname:\n",
    "    fig.savefig(figname)\n",
    "  plt.close()\n",
    "  print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_folder already exist\n"
     ]
    }
   ],
   "source": [
    "gene_blocklist = [\n",
    "    {'kernel':3, 'out_channel':256, 'stride':2},\n",
    "    {'kernel':3, 'out_channel':128, 'stride':2},\n",
    "    {'kernel':3, 'out_channel':64,  'stride':2},\n",
    "]\n",
    "block_list = [\n",
    "    {'kernel':3, 'out_channel':128, 'stride':2},\n",
    "    {'kernel':3, 'out_channel':256, 'stride':2},\n",
    "    {'kernel':3, 'out_channel':256, 'stride':2},\n",
    "]\n",
    "device = 'cuda'\n",
    "batchsize = 64\n",
    "maxiter = 1e5\n",
    "use_tensorboard = False \n",
    "load = False\n",
    "iteration = 0\n",
    "checkpoint_folder = 'LSUN_CHURCH/checkpoint'\n",
    "try:\n",
    "    os.makedirs(os.path.join('./',checkpoint_folder))\n",
    "except:\n",
    "  print('checkpoint_folder already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------build model and optimizer-------------------------------------------\n",
    "gene64 = Generator(128,blocklist=gene_blocklist, figsize=64, device=device)\n",
    "#gene64 = wgan_gp.Generator().to(device)\n",
    "dis64 = Discriminator(64, blocklist=block_list, device=device, use_res=True)\n",
    "#dis64 = wgan_gp.Discriminator().to(device)\n",
    "optim_g = torch.optim.Adam(gene64.parameters(), lr=2e-4)\n",
    "optim_d = torch.optim.Adam(dis64.parameters(), lr=2e-4)\n",
    "\n",
    "#--------------------------------------train iteration--------------------------------------------------------\n",
    "if load:\n",
    "    gene64.load_state_dict(torch.load('./LSUN_CHURCH/checkpoint/gene_checkpoint_4000.pth'))\n",
    "    dis64.load_state_dict(torch.load('./LSUN_CHURCH/checkpoint/dis_checkpoint_4000.pth'))\n",
    "if use_tensorboard:\n",
    "    writer = SummaryWriter('./runs/exp2-LSUN/train_{}'.format(datetime.datetime.now().strftime(\"%Y%m%d_%H_%M_%S\")))\n",
    "    writer.add_graph(dis64, gene64(torch.randn(1,128,device=device)))   #show graph of discriminator in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "sampin = torch.randn(1, 128, device=device)\n",
    "fake_fig = gene64(sampin)*0.5 + 0.5\n",
    "plotsamp(fake_fig.cpu().squeeze().detach().numpy(), 'out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import datetime, os\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), \n",
    "])\n",
    "'''NPY数据格式'''\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = np.load(data) #加载npy数据\n",
    "        self.data = np.transpose(self.data, (0, 3, 1, 2))\n",
    "        self.data = torch.from_numpy(self.data)\n",
    "        self.data = self.data.to(device)\n",
    "        self.transforms = transform\n",
    "    def __getitem__(self, index):\n",
    "        hdct = self.data[index, :, :, :]  # 读取每一个npy的数据\n",
    "        hdct = hdct/128 - 1\n",
    "        return hdct, 0 #返回数据还有标签\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] #返回数据的总个数\n",
    "\n",
    "#-------------------------------------load and transform dataset------------------------------------------\n",
    "set = MyDataset('./data/LSUN/church_outdoor_train_lmdb_color_64.npy')\n",
    "train_set, test_set = torch.utils.data.random_split(set, [len(set)//5*4, len(set)-len(set)//5*4])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batchsize, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HqvduyQWwJBu",
    "outputId": "bbf9645f-2f3a-4c7c-d814-ed9d0755fd88"
   },
   "outputs": [],
   "source": [
    "while iteration < maxiter:\n",
    "    for i_imag, image in enumerate(train_loader):#need reconstruction using iterator\n",
    "        real_data = image[0].to(device)\n",
    "        randin = torch.randn(batchsize, 128, device=device)\n",
    "        gradloss = train_discrminator(dis64, real_data, gene64(randin), optim_d, device=device)\n",
    "        #train discriminator 5 times each iteration\n",
    "        if i_imag%5 == 0:\n",
    "            iteration += 1\n",
    "            train_generator(gene64, dis64, randin, optim_g)\n",
    "            #sample generator every 100 iter\n",
    "            if iteration%100 == 99:\n",
    "                if iteration%100 == 99:\n",
    "                  gene64.eval()\n",
    "                  dis64.eval()\n",
    "                  with torch.no_grad():\n",
    "                        #cal D score on test D_score = mean(D(testdata))'\n",
    "                        d_score = 0\n",
    "                        for image in test_loader:\n",
    "                            real_imag = image[0].to(device)\n",
    "                            d_score -= dis64(real_imag).sum().item()\n",
    "                        if use_tensorboard:\n",
    "                            print(f'iter:{iteration+1}', end='\\r')\n",
    "                            sampin = torch.randn(5, 128, device=device)\n",
    "                            fake_fig = gene64(sampin)*0.5 + 0.5 #transform back to standard rgb\n",
    "                            writer.add_images('gene', torch.concat([fake_fig, real_data[0,...].unsqueeze(0)*0.5+0.5], dim=0), global_step=iteration)\n",
    "                            writer.add_scalar('d_score', d_score/len(test_set), iteration)\n",
    "                        else:\n",
    "                            print(f'iter:{iteration+1}  d_score:{d_score/len(test_set)}')\n",
    "                            with open('g_score.txt', mode='a') as f:\n",
    "                                f.write(','.join(map(str, [iteration+1, dis64(gene64(torch.randn(batchsize*10, 128, device=device))).mean().item()])),'\\n')\n",
    "                            with open('d_score.txt', mode='a') as f:\n",
    "                                f.write(','.join(map(str, [iteration+1, d_score/len(test_set)])),'\\n')\n",
    "                            sampin = torch.randn(1, 128, device=device)\n",
    "                            fake_fig = gene64(sampin)*0.5 + 0.5 #transform back to standard rgb\n",
    "                            plotsamp(fake_fig.cpu().squeeze().detach().numpy(), f'{iteration+1}_gene.png')\n",
    "            if iteration%100 == 99:\n",
    "                torch.save(gene64.state_dict(), os.path.join(os.getcwd(), checkpoint_folder, 'gene_checkpoint_last.pth'))\n",
    "                torch.save(dis64.state_dict(), os.path.join(os.getcwd(), checkpoint_folder, 'dis_checkpoint_last.pth'))\n",
    "            if iteration%1000 == 1000-1:\n",
    "                torch.save(gene64.state_dict(), os.path.join(os.getcwd(), checkpoint_folder, f'gene_checkpoint_{iteration+1}.pth'))\n",
    "                torch.save(dis64.state_dict(), os.path.join(os.getcwd(), checkpoint_folder, f'dis_checkpoint_{iteration+1}.pth'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trainlsun.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
